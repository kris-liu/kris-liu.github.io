<!DOCTYPE html><html lang="zh-CN"><head><meta name="google-site-verification" content="DVfrDhwMEodDoWVy6nv0PCpolWhBlGBSaO9hiU2r61E"><meta name="google-site-verification" content="40TgWkMJTOetJQqAMZwk5nD5rtVQRjk5i2pe6FGka5g"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Liu Xin's Blog"><title>由一次kafka消费端消息阻塞问题分析kafka消费端线程模型 | Liu Xin's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-91282031-1','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">由一次kafka消费端消息阻塞问题分析kafka消费端线程模型</h1><a id="logo" href="/.">Liu Xin's Blog</a><p class="description">Whatever you do, you have to keep moving forward!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">由一次kafka消费端消息阻塞问题分析kafka消费端线程模型</h1><div class="post-meta">Aug 11, 2018<span> | </span><span class="category"><a href="/categories/线上问题/">线上问题</a></span></div><div class="post-content"><p>最近线上有个需求希望能停止kafka消费某个topic一段时间，结果导致将该系统消费的所有topic都阻塞掉了。</p>
<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>首先介绍下该系统consumer的配置，该系统启动了一个ConsumerConnector，使用1个group同时消费3个topic，每个topic分配了一定数量的消费线程。改造的方案是在消费线程每次调用hasNext方法获取消息前，通过一个动态配置控制线程sleep一段时间。发布上线后推送配置关闭其中1个topic的时候，通过监控发现，其他所有的3个topic全部都停止了消息消费，回滚了配置后，所有topic才又开始继续消费。为什么一个topic的消费线程sleep，会影响所有topic的消息消费呢？</p>
<h3 id="问题排查定位过程"><a href="#问题排查定位过程" class="headerlink" title="问题排查定位过程"></a>问题排查定位过程</h3><p>根据当时情况想到的几种可能：一个是开关逻辑有bug，原本一个开关控制一个topic的情况变成一个开关控制所有topic是否消费了，通过日志以及jstack线程快照很快排除了这一点，开关逻辑确认没有bug；再就是怀疑kafkaconsumer的client内部是不是有什么内存缓冲队列之类的东西导致阻塞了其他的topic，为了验证这一点，我们获取了当时异常期间的线程快照，以及kafkaclient的源码。</p>
<p>首先来看线程快照中其他topic的消费线程堆栈：</p>
<p><img src="/2018/08/11/kafka-block/WorkThread.png" alt="消费线程"></p>
<p>根据线程名称，发现我们创建的消息消费线程停在了hasNext方法上，便排除了开关逻辑bug，更深的堆栈发现消费线程阻塞在了LinkedBlockingQueue的take方法上，说明该队列中已无消息，既然hasNext方法是从一个LinkedBlockingQueue上获取消息，那么也就是说kafka一定是有单独的线程来拉取消息然后put到这个LinkedBlockingQueue的，根据经验，一般第三方组件内线程都会设定特定名字，或者能从堆栈中一些第三方包路径找到第三方组件的涉及的线程堆栈，于是便找到了下面的堆栈：</p>
<p><img src="/2018/08/11/kafka-block/ConsumerFetcherThread.png" alt="消息拉取线程"></p>
<p>发现有个ConsumerFetcherThread阻塞在了LinkedBlockingQueue的put方法上。消费线程阻塞在take方法，这里阻塞在put方法，说明这还不是同一个LinkedBlockingQueue。</p>
<p>为了搞清楚这两个LinkedBlockingQueue到底都是做什么的，便需要通过源码来查看了，下载对应版本的kafka的源码，跟踪kafka源码还需要下载scala还有gradle，还有idea的scala插件。在阻塞线程的线程堆栈的指引下，对源码进行跟踪排查：</p>
<p>消费线程阻塞相关代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>(): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">if</span>(state == <span class="type">FAILED</span>)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Iterator is in failed state"</span>)</div><div class="line">  state <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">DONE</span> =&gt; <span class="literal">false</span></div><div class="line">    <span class="keyword">case</span> <span class="type">READY</span> =&gt; <span class="literal">true</span></div><div class="line">    <span class="keyword">case</span> _ =&gt; maybeComputeNext()</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeComputeNext</span></span>(): <span class="type">Boolean</span> = &#123;</div><div class="line">  state = <span class="type">FAILED</span></div><div class="line">  nextItem = makeNext()</div><div class="line">  <span class="keyword">if</span>(state == <span class="type">DONE</span>) &#123;</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    state = <span class="type">READY</span></div><div class="line">    <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">makeNext</span></span>(): <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>] = &#123;</div><div class="line">  <span class="keyword">var</span> currentDataChunk: <span class="type">FetchedDataChunk</span> = <span class="literal">null</span></div><div class="line">  <span class="comment">// if we don't have an iterator, get one</span></div><div class="line">  <span class="keyword">var</span> localCurrent = current.get()</div><div class="line">  <span class="keyword">if</span>(localCurrent == <span class="literal">null</span> || !localCurrent.hasNext) &#123;</div><div class="line">    <span class="keyword">if</span> (consumerTimeoutMs &lt; <span class="number">0</span>)</div><div class="line">      currentDataChunk = channel.take</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      currentDataChunk = channel.poll(consumerTimeoutMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">      <span class="keyword">if</span> (currentDataChunk == <span class="literal">null</span>) &#123;</div><div class="line">        <span class="comment">// reset state to make the iterator re-iterable</span></div><div class="line">        resetState()</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ConsumerTimeoutException</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span>(currentDataChunk eq <span class="type">ZookeeperConsumerConnector</span>.shutdownCommand) &#123;</div><div class="line">      debug(<span class="string">"Received the shutdown command"</span>)</div><div class="line">      <span class="keyword">return</span> allDone</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      currentTopicInfo = currentDataChunk.topicInfo</div><div class="line">      <span class="keyword">val</span> cdcFetchOffset = currentDataChunk.fetchOffset</div><div class="line">      <span class="keyword">val</span> ctiConsumeOffset = currentTopicInfo.getConsumeOffset</div><div class="line">      <span class="keyword">if</span> (ctiConsumeOffset &lt; cdcFetchOffset) &#123;</div><div class="line">        error(<span class="string">"consumed offset: %d doesn't match fetch offset: %d for %s;\n Consumer may lose data"</span></div><div class="line">          .format(ctiConsumeOffset, cdcFetchOffset, currentTopicInfo))</div><div class="line">        currentTopicInfo.resetConsumeOffset(cdcFetchOffset)</div><div class="line">      &#125;</div><div class="line">      localCurrent = currentDataChunk.messages.iterator</div><div class="line"></div><div class="line">      current.set(localCurrent)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// if we just updated the current chunk and it is empty that means the fetch size is too small!</span></div><div class="line">    <span class="keyword">if</span>(currentDataChunk.messages.validBytes == <span class="number">0</span>)</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">MessageSizeTooLargeException</span>(<span class="string">"Found a message larger than the maximum fetch size of this consumer on topic "</span> +</div><div class="line">                                             <span class="string">"%s partition %d at fetch offset %d. Increase the fetch size, or decrease the maximum message size the broker will allow."</span></div><div class="line">                                             .format(currentDataChunk.topicInfo.topic, currentDataChunk.topicInfo.partitionId, currentDataChunk.fetchOffset))</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">var</span> item = localCurrent.next()</div><div class="line">  <span class="comment">// reject the messages that have already been consumed</span></div><div class="line">  <span class="keyword">while</span> (item.offset &lt; currentTopicInfo.getConsumeOffset &amp;&amp; localCurrent.hasNext) &#123;</div><div class="line">    item = localCurrent.next()</div><div class="line">  &#125;</div><div class="line">  consumedOffset = item.nextOffset</div><div class="line"></div><div class="line">  item.message.ensureValid() <span class="comment">// validate checksum of message to ensure it is valid</span></div><div class="line"></div><div class="line">  <span class="keyword">new</span> <span class="type">MessageAndMetadata</span>(currentTopicInfo.topic, currentTopicInfo.partitionId, item.message, item.offset, keyDecoder, valueDecoder)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>makeNext方法会从channel取出一个FetchedDataChunk，放入本地变量current中，每次获取元素再优先从current上获取，一个FetchedDataChunk内部包含了多条消息，这里消费线程阻塞在makeNext方法的channel.take处，这个channel是ConsumerIterator构造方法传入的，找到创建ConsumerIterator的地方</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>](<span class="params">private val queue: <span class="type">BlockingQueue</span>[<span class="type">FetchedDataChunk</span>],</span></span></div><div class="line">                        consumerTimeoutMs: <span class="type">Int</span>,</div><div class="line">                        private val keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>],</div><div class="line">                        private val valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>],</div><div class="line">                        val clientId: <span class="type">String</span>)</div><div class="line">   <span class="keyword">extends</span> <span class="type">Iterable</span>[<span class="type">MessageAndMetadata</span>[<span class="type">K</span>,<span class="type">V</span>]] <span class="keyword">with</span> java.lang.<span class="type">Iterable</span>[<span class="type">MessageAndMetadata</span>[<span class="type">K</span>,<span class="type">V</span>]] &#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> iter: <span class="type">ConsumerIterator</span>[<span class="type">K</span>,<span class="type">V</span>] =</div><div class="line">    <span class="keyword">new</span> <span class="type">ConsumerIterator</span>[<span class="type">K</span>,<span class="type">V</span>](queue, consumerTimeoutMs, keyDecoder, valueDecoder, clientId)</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   *  Create an iterator over messages in the stream.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">iterator</span></span>(): <span class="type">ConsumerIterator</span>[<span class="type">K</span>,<span class="type">V</span>] = iter</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个队列是在创建KafkaStream时传入的，需要看下KafkaStream如何创建，从createMessageStreams方法看起</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createMessageStreams</span></span>[<span class="type">K</span>,<span class="type">V</span>](</div><div class="line">      topicCountMap: java.util.<span class="type">Map</span>[<span class="type">String</span>,java.lang.<span class="type">Integer</span>],</div><div class="line">      keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>],</div><div class="line">      valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>])</div><div class="line">    : java.util.<span class="type">Map</span>[<span class="type">String</span>,java.util.<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]] = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (messageStreamCreated.getAndSet(<span class="literal">true</span>))</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">MessageStreamsExistException</span>(<span class="keyword">this</span>.getClass.getSimpleName +</div><div class="line">                                 <span class="string">" can create message streams at most once"</span>,<span class="literal">null</span>)</div><div class="line">  <span class="keyword">val</span> scalaTopicCountMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = &#123;</div><div class="line">    <span class="keyword">import</span> <span class="type">JavaConversions</span>._</div><div class="line">    <span class="type">Map</span>.empty[<span class="type">String</span>, <span class="type">Int</span>] ++ (topicCountMap.asInstanceOf[java.util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>]]: mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>])</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">val</span> scalaReturn = underlying.consume(scalaTopicCountMap, keyDecoder, valueDecoder)</div><div class="line">  <span class="keyword">val</span> ret = <span class="keyword">new</span> java.util.<span class="type">HashMap</span>[<span class="type">String</span>,java.util.<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]</div><div class="line">  <span class="keyword">for</span> ((topic, streams) &lt;- scalaReturn) &#123;</div><div class="line">    <span class="keyword">var</span> javaStreamList = <span class="keyword">new</span> java.util.<span class="type">ArrayList</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]</div><div class="line">    <span class="keyword">for</span> (stream &lt;- streams)</div><div class="line">      javaStreamList.add(stream)</div><div class="line">    ret.put(topic, javaStreamList)</div><div class="line">  &#125;</div><div class="line">  ret</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consume</span></span>[<span class="type">K</span>, <span class="type">V</span>](topicCountMap: scala.collection.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>], keyDecoder: <span class="type">Decoder</span>[<span class="type">K</span>], valueDecoder: <span class="type">Decoder</span>[<span class="type">V</span>])</div><div class="line">    : <span class="type">Map</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]] = &#123;</div><div class="line">  debug(<span class="string">"entering consume "</span>)</div><div class="line">  <span class="keyword">if</span> (topicCountMap == <span class="literal">null</span>)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>(<span class="string">"topicCountMap is null"</span>)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> topicCount = <span class="type">TopicCount</span>.constructTopicCount(consumerIdString, topicCountMap)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> topicThreadIds = topicCount.getConsumerThreadIdsPerTopic</div><div class="line"></div><div class="line">  <span class="comment">// make a list of (queue,stream) pairs, one pair for each threadId</span></div><div class="line">  <span class="keyword">val</span> queuesAndStreams = topicThreadIds.values.map(threadIdSet =&gt;</div><div class="line">    threadIdSet.map(_ =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> queue =  <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">FetchedDataChunk</span>](config.queuedMaxMessages)</div><div class="line">      <span class="keyword">val</span> stream = <span class="keyword">new</span> <span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>](</div><div class="line">        queue, config.consumerTimeoutMs, keyDecoder, valueDecoder, config.clientId)</div><div class="line">      (queue, stream)</div><div class="line">    &#125;)</div><div class="line">  ).flatten.toList</div><div class="line"></div><div class="line">  <span class="keyword">val</span> dirs = <span class="keyword">new</span> <span class="type">ZKGroupDirs</span>(config.groupId)</div><div class="line">  registerConsumerInZK(dirs, consumerIdString, topicCount)</div><div class="line">  reinitializeConsumer(topicCount, queuesAndStreams)</div><div class="line"></div><div class="line">  loadBalancerListener.kafkaMessageAndMetadataStreams.asInstanceOf[<span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>topicThreadIds的key是topic，value是根据消费线程数量产生的对应大小的集合，根据topicThreadIds创建了queuesAndStreams，queuesAndStreams的ket是topic，value是消费线程对应的KafkaStream集合，一个消费线程对应一个KafkaStream，一个KafkaStream对应一个LinkedBlockingQueue，大小由queued.max.message.chunks参数指定，默认是2，也就是说各个消费线程hasNext方法阻塞逻辑使用的队列是相互隔离的。继续往下看，registerConsumerInZK方法主要是将消费者相关信息注册在zk上，reinitializeConsumer方法初始化具体的consumer。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">reinitializeConsumer</span></span>[<span class="type">K</span>,<span class="type">V</span>](</div><div class="line">    topicCount: <span class="type">TopicCount</span>,</div><div class="line">    queuesAndStreams: <span class="type">List</span>[(<span class="type">LinkedBlockingQueue</span>[<span class="type">FetchedDataChunk</span>],<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>])]) &#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> dirs = <span class="keyword">new</span> <span class="type">ZKGroupDirs</span>(config.groupId)</div><div class="line"></div><div class="line">  <span class="comment">// listener to consumer and partition changes</span></div><div class="line">  <span class="keyword">if</span> (loadBalancerListener == <span class="literal">null</span>) &#123;</div><div class="line">    <span class="keyword">val</span> topicStreamsMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>,<span class="type">List</span>[<span class="type">KafkaStream</span>[<span class="type">K</span>,<span class="type">V</span>]]]</div><div class="line">    loadBalancerListener = <span class="keyword">new</span> <span class="type">ZKRebalancerListener</span>(</div><div class="line">      config.groupId, consumerIdString, topicStreamsMap.asInstanceOf[scala.collection.mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">KafkaStream</span>[_,_]]]])</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// create listener for session expired event if not exist yet</span></div><div class="line">  <span class="keyword">if</span> (sessionExpirationListener == <span class="literal">null</span>)</div><div class="line">    sessionExpirationListener = <span class="keyword">new</span> <span class="type">ZKSessionExpireListener</span>(</div><div class="line">      dirs, consumerIdString, topicCount, loadBalancerListener)</div><div class="line"></div><div class="line">  <span class="comment">// create listener for topic partition change event if not exist yet</span></div><div class="line">  <span class="keyword">if</span> (topicPartitionChangeListener == <span class="literal">null</span>)</div><div class="line">    topicPartitionChangeListener = <span class="keyword">new</span> <span class="type">ZKTopicPartitionChangeListener</span>(loadBalancerListener)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> topicStreamsMap = loadBalancerListener.kafkaMessageAndMetadataStreams</div><div class="line"></div><div class="line">  <span class="comment">// map of &#123;topic -&gt; Set(thread-1, thread-2, ...)&#125;</span></div><div class="line">  <span class="keyword">val</span> consumerThreadIdsPerTopic: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Set</span>[<span class="type">ConsumerThreadId</span>]] =</div><div class="line">    topicCount.getConsumerThreadIdsPerTopic</div><div class="line"></div><div class="line">  <span class="keyword">val</span> allQueuesAndStreams = topicCount <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> wildTopicCount: <span class="type">WildcardTopicCount</span> =&gt;</div><div class="line">      <span class="comment">/*</span></div><div class="line">       * Wild-card consumption streams share the same queues, so we need to</div><div class="line">       * duplicate the list for the subsequent zip operation.</div><div class="line">       */</div><div class="line">      (<span class="number">1</span> to consumerThreadIdsPerTopic.keySet.size).flatMap(_ =&gt; queuesAndStreams).toList</div><div class="line">    <span class="keyword">case</span> statTopicCount: <span class="type">StaticTopicCount</span> =&gt;</div><div class="line">      queuesAndStreams</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> topicThreadIds = consumerThreadIdsPerTopic.map &#123;</div><div class="line">    <span class="keyword">case</span>(topic, threadIds) =&gt;</div><div class="line">      threadIds.map((topic, _))</div><div class="line">  &#125;.flatten</div><div class="line"></div><div class="line">  require(topicThreadIds.size == allQueuesAndStreams.size,</div><div class="line">    <span class="string">"Mismatch between thread ID count (%d) and queue count (%d)"</span></div><div class="line">    .format(topicThreadIds.size, allQueuesAndStreams.size))</div><div class="line">  <span class="keyword">val</span> threadQueueStreamPairs = topicThreadIds.zip(allQueuesAndStreams)</div><div class="line"></div><div class="line">  threadQueueStreamPairs.foreach(e =&gt; &#123;</div><div class="line">    <span class="keyword">val</span> topicThreadId = e._1</div><div class="line">    <span class="keyword">val</span> q = e._2._1</div><div class="line">    topicThreadIdAndQueues.put(topicThreadId, q)</div><div class="line">    debug(<span class="string">"Adding topicThreadId %s and queue %s to topicThreadIdAndQueues data structure"</span>.format(topicThreadId, q.toString))</div><div class="line">    newGauge(</div><div class="line">      <span class="string">"FetchQueueSize"</span>,</div><div class="line">      <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">value</span> </span>= q.size</div><div class="line">      &#125;,</div><div class="line">      <span class="type">Map</span>(<span class="string">"clientId"</span> -&gt; config.clientId,</div><div class="line">        <span class="string">"topic"</span> -&gt; topicThreadId._1,</div><div class="line">        <span class="string">"threadId"</span> -&gt; topicThreadId._2.threadId.toString)</div><div class="line">    )</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> groupedByTopic = threadQueueStreamPairs.groupBy(_._1._1)</div><div class="line">  groupedByTopic.foreach(e =&gt; &#123;</div><div class="line">    <span class="keyword">val</span> topic = e._1</div><div class="line">    <span class="keyword">val</span> streams = e._2.map(_._2._2).toList</div><div class="line">    topicStreamsMap += (topic -&gt; streams)</div><div class="line">    debug(<span class="string">"adding topic %s and %d streams to map."</span>.format(topic, streams.size))</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  <span class="comment">// listener to consumer and partition changes</span></div><div class="line">  zkClient.subscribeStateChanges(sessionExpirationListener)</div><div class="line"></div><div class="line">  zkClient.subscribeChildChanges(dirs.consumerRegistryDir, loadBalancerListener)</div><div class="line"></div><div class="line">  topicStreamsMap.foreach &#123; topicAndStreams =&gt;</div><div class="line">    <span class="comment">// register on broker partition path changes</span></div><div class="line">    <span class="keyword">val</span> topicPath = <span class="type">BrokerTopicsPath</span> + <span class="string">"/"</span> + topicAndStreams._1</div><div class="line">    zkClient.subscribeDataChanges(topicPath, topicPartitionChangeListener)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// explicitly trigger load balancing for this consumer</span></div><div class="line">  loadBalancerListener.syncedRebalance()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>reinitializeConsumer方法首先创建了一些用于负载均衡超时等相关逻辑的zk监听；然后根据topicThreadIds和queuesAndStreams创建了topicThreadIdAndQueues，topicThreadIdAndQueues的key是topic+线程号组成的key，value是线程对应的KafkaStream里的LinkedBlockingQueue；然后注册了zk监听；最后通过syncedRebalance做第一次的初始化动作</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">syncedRebalance</span></span>() &#123;</div><div class="line">  rebalanceLock synchronized &#123;</div><div class="line">    rebalanceTimer.time &#123;</div><div class="line">      <span class="keyword">if</span>(isShuttingDown.get())  &#123;</div><div class="line">        <span class="keyword">return</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until config.rebalanceMaxRetries) &#123;</div><div class="line">          info(<span class="string">"begin rebalancing consumer "</span> + consumerIdString + <span class="string">" try #"</span> + i)</div><div class="line">          <span class="keyword">var</span> done = <span class="literal">false</span></div><div class="line">          <span class="keyword">var</span> cluster: <span class="type">Cluster</span> = <span class="literal">null</span></div><div class="line">          <span class="keyword">try</span> &#123;</div><div class="line">            cluster = getCluster(zkClient)</div><div class="line">            done = rebalance(cluster)</div><div class="line">          &#125; <span class="keyword">catch</span> &#123;</div><div class="line">            <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">              <span class="comment">/** occasionally, we may hit a ZK exception because the ZK state is changing while we are iterating.</span></div><div class="line">                * For example, a ZK node can disappear between the time we get all children and the time we try to get</div><div class="line">                * the value of a child. Just let this go since another rebalance will be triggered.</div><div class="line">                **/</div><div class="line">              info(<span class="string">"exception during rebalance "</span>, e)</div><div class="line">          &#125;</div><div class="line">          info(<span class="string">"end rebalancing consumer "</span> + consumerIdString + <span class="string">" try #"</span> + i)</div><div class="line">          <span class="keyword">if</span> (done) &#123;</div><div class="line">            <span class="keyword">return</span></div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">/* Here the cache is at a risk of being stale. To take future rebalancing decisions correctly, we should</span></div><div class="line">             * clear the cache */</div><div class="line">            info(<span class="string">"Rebalancing attempt failed. Clearing the cache before the next rebalancing operation is triggered"</span>)</div><div class="line">          &#125;</div><div class="line">          <span class="comment">// stop all fetchers and clear all the queues to avoid data duplication</span></div><div class="line">          closeFetchersForQueues(cluster, kafkaMessageAndMetadataStreams, topicThreadIdAndQueues.map(q =&gt; q._2))</div><div class="line">          <span class="type">Thread</span>.sleep(config.rebalanceBackoffMs)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ConsumerRebalanceFailedException</span>(consumerIdString + <span class="string">" can't rebalance after "</span> + config.rebalanceMaxRetries +<span class="string">" retries"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">rebalance</span></span>(cluster: <span class="type">Cluster</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">val</span> myTopicThreadIdsMap = <span class="type">TopicCount</span>.constructTopicCount(</div><div class="line">    group, consumerIdString, zkClient, config.excludeInternalTopics).getConsumerThreadIdsPerTopic</div><div class="line">  <span class="keyword">val</span> brokers = getAllBrokersInCluster(zkClient)</div><div class="line">  <span class="keyword">if</span> (brokers.size == <span class="number">0</span>) &#123;</div><div class="line">    <span class="comment">// This can happen in a rare case when there are no brokers available in the cluster when the consumer is started.</span></div><div class="line">    <span class="comment">// We log an warning and register for child changes on brokers/id so that rebalance can be triggered when the brokers</span></div><div class="line">    <span class="comment">// are up.</span></div><div class="line">    warn(<span class="string">"no brokers found when trying to rebalance."</span>)</div><div class="line">    zkClient.subscribeChildChanges(<span class="type">ZkUtils</span>.<span class="type">BrokerIdsPath</span>, loadBalancerListener)</div><div class="line">    <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line">  <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">/**</span></div><div class="line">     * fetchers must be stopped to avoid data duplication, since if the current</div><div class="line">     * rebalancing attempt fails, the partitions that are released could be owned by another consumer.</div><div class="line">     * But if we don't stop the fetchers first, this consumer would continue returning data for released</div><div class="line">     * partitions in parallel. So, not stopping the fetchers leads to duplicate data.</div><div class="line">     */</div><div class="line">    closeFetchers(cluster, kafkaMessageAndMetadataStreams, myTopicThreadIdsMap)</div><div class="line"></div><div class="line">    releasePartitionOwnership(topicRegistry)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> assignmentContext = <span class="keyword">new</span> <span class="type">AssignmentContext</span>(group, consumerIdString, config.excludeInternalTopics, zkClient)</div><div class="line">    <span class="keyword">val</span> partitionOwnershipDecision = partitionAssignor.assign(assignmentContext)</div><div class="line">    <span class="keyword">val</span> currentTopicRegistry = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">String</span>, <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]](</div><div class="line">      valueFactory = <span class="type">Some</span>((topic: <span class="type">String</span>) =&gt; <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">Int</span>, <span class="type">PartitionTopicInfo</span>]))</div><div class="line"></div><div class="line">    <span class="comment">// fetch current offsets for all topic-partitions</span></div><div class="line">    <span class="keyword">val</span> topicPartitions = partitionOwnershipDecision.keySet.toSeq</div><div class="line"></div><div class="line">    <span class="keyword">val</span> offsetFetchResponseOpt = fetchOffsets(topicPartitions)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (isShuttingDown.get || !offsetFetchResponseOpt.isDefined)</div><div class="line">      <span class="literal">false</span></div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">val</span> offsetFetchResponse = offsetFetchResponseOpt.get</div><div class="line">      topicPartitions.foreach(topicAndPartition =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> (topic, partition) = topicAndPartition.asTuple</div><div class="line">        <span class="keyword">val</span> offset = offsetFetchResponse.requestInfo(topicAndPartition).offset</div><div class="line">        <span class="keyword">val</span> threadId = partitionOwnershipDecision(topicAndPartition)</div><div class="line">        addPartitionTopicInfo(currentTopicRegistry, partition, topic, offset, threadId)</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">/**</span></div><div class="line">       * move the partition ownership here, since that can be used to indicate a truly successful rebalancing attempt</div><div class="line">       * A rebalancing attempt is completed successfully only after the fetchers have been started correctly</div><div class="line">       */</div><div class="line">      <span class="keyword">if</span>(reflectPartitionOwnershipDecision(partitionOwnershipDecision)) &#123;</div><div class="line">        allTopicsOwnedPartitionsCount = partitionOwnershipDecision.size</div><div class="line"></div><div class="line">        partitionOwnershipDecision.view.groupBy &#123; <span class="keyword">case</span>(topicPartition, consumerThreadId) =&gt; topicPartition.topic &#125;</div><div class="line">                                  .foreach &#123; <span class="keyword">case</span> (topic, partitionThreadPairs) =&gt;</div><div class="line">          newGauge(<span class="string">"OwnedPartitionsCount"</span>,</div><div class="line">            <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">              <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>() = partitionThreadPairs.size</div><div class="line">            &#125;,</div><div class="line">            ownedPartitionsCountMetricTags(topic))</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        topicRegistry = currentTopicRegistry</div><div class="line">        updateFetcher(cluster)</div><div class="line">        <span class="literal">true</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="literal">false</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>主要关注currentTopicRegistry的初始化相关逻辑，topicPartitions是从zk上获取到了当前机器分配到的所有partition分区，通过topicPartitions来创建currentTopicRegistry，currentTopicRegistry的key是topic，value是个map，key是partition，value是PartitionTopicInfo，PartitionTopicInfo包含了topic，partition，消费线程对应的LinkedBlockingQueue，还有一些offset等信息。看核心的updateFetcher方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateFetcher</span></span>(cluster: <span class="type">Cluster</span>) &#123;</div><div class="line">  <span class="comment">// update partitions for fetcher</span></div><div class="line">  <span class="keyword">var</span> allPartitionInfos : <span class="type">List</span>[<span class="type">PartitionTopicInfo</span>] = <span class="type">Nil</span></div><div class="line">  <span class="keyword">for</span> (partitionInfos &lt;- topicRegistry.values)</div><div class="line">    <span class="keyword">for</span> (partition &lt;- partitionInfos.values)</div><div class="line">      allPartitionInfos ::= partition</div><div class="line">  info(<span class="string">"Consumer "</span> + consumerIdString + <span class="string">" selected partitions : "</span> +</div><div class="line">    allPartitionInfos.sortWith((s,t) =&gt; s.partitionId &lt; t.partitionId).map(_.toString).mkString(<span class="string">","</span>))</div><div class="line"></div><div class="line">  fetcher <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(f) =&gt;</div><div class="line">      f.startConnections(allPartitionInfos, cluster)</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>根据TopicRegistry创建allPartitionInfos，allPartitionInfos是所有PartitionTopicInfo的列表，然后开始连接逻辑</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">startConnections</span></span>(topicInfos: <span class="type">Iterable</span>[<span class="type">PartitionTopicInfo</span>], cluster: <span class="type">Cluster</span>) &#123;</div><div class="line">  leaderFinderThread = <span class="keyword">new</span> <span class="type">LeaderFinderThread</span>(consumerIdString + <span class="string">"-leader-finder-thread"</span>)</div><div class="line">  leaderFinderThread.start()</div><div class="line"></div><div class="line">  inLock(lock) &#123;</div><div class="line">    partitionMap = topicInfos.map(tpi =&gt; (<span class="type">TopicAndPartition</span>(tpi.topic, tpi.partitionId), tpi)).toMap</div><div class="line">    <span class="keyword">this</span>.cluster = cluster</div><div class="line">    noLeaderPartitionSet ++= topicInfos.map(tpi =&gt; <span class="type">TopicAndPartition</span>(tpi.topic, tpi.partitionId))</div><div class="line">    cond.signalAll()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>创建LeaderFinderThread线程用于开启连接，然后将之前的allPartitionInfos转化成partitionMap，partitionMap的key是topic+partitionId，value是PartitionTopicInfo，这个partitionMap在后面有用处，看下LeaderFinderThread的逻辑</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>() &#123;</div><div class="line">    <span class="keyword">val</span> leaderForPartitionsMap = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">TopicAndPartition</span>, <span class="type">Broker</span>]</div><div class="line">    lock.lock()</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">while</span> (noLeaderPartitionSet.isEmpty) &#123;</div><div class="line">        trace(<span class="string">"No partition for leader election."</span>)</div><div class="line">        cond.await()</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      trace(<span class="string">"Partitions without leader %s"</span>.format(noLeaderPartitionSet))</div><div class="line">      <span class="keyword">val</span> brokers = getAllBrokersInCluster(zkClient)</div><div class="line">      <span class="keyword">val</span> topicsMetadata = <span class="type">ClientUtils</span>.fetchTopicMetadata(noLeaderPartitionSet.map(m =&gt; m.topic).toSet,</div><div class="line">                                                          brokers,</div><div class="line">                                                          config.clientId,</div><div class="line">                                                          config.socketTimeoutMs,</div><div class="line">                                                          correlationId.getAndIncrement).topicsMetadata</div><div class="line">      <span class="keyword">if</span>(logger.isDebugEnabled) topicsMetadata.foreach(topicMetadata =&gt; debug(topicMetadata.toString()))</div><div class="line">      topicsMetadata.foreach &#123; tmd =&gt;</div><div class="line">        <span class="keyword">val</span> topic = tmd.topic</div><div class="line">        tmd.partitionsMetadata.foreach &#123; pmd =&gt;</div><div class="line">          <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(topic, pmd.partitionId)</div><div class="line">          <span class="keyword">if</span>(pmd.leader.isDefined &amp;&amp; noLeaderPartitionSet.contains(topicAndPartition)) &#123;</div><div class="line">            <span class="keyword">val</span> leaderBroker = pmd.leader.get</div><div class="line">            leaderForPartitionsMap.put(topicAndPartition, leaderBroker)</div><div class="line">            noLeaderPartitionSet -= topicAndPartition</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt; &#123;</div><div class="line">          <span class="keyword">if</span> (!isRunning.get())</div><div class="line">            <span class="keyword">throw</span> t <span class="comment">/* If this thread is stopped, propagate this exception to kill the thread. */</span></div><div class="line">          <span class="keyword">else</span></div><div class="line">            warn(<span class="string">"Failed to find leader for %s"</span>.format(noLeaderPartitionSet), t)</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      lock.unlock()</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      addFetcherForPartitions(leaderForPartitionsMap.map&#123;</div><div class="line">        <span class="keyword">case</span> (topicAndPartition, broker) =&gt;</div><div class="line">          topicAndPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(broker, partitionMap(topicAndPartition).getFetchOffset())&#125;</div><div class="line">      )</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt; &#123;</div><div class="line">        <span class="keyword">if</span> (!isRunning.get())</div><div class="line">          <span class="keyword">throw</span> t <span class="comment">/* If this thread is stopped, propagate this exception to kill the thread. */</span></div><div class="line">        <span class="keyword">else</span> &#123;</div><div class="line">          warn(<span class="string">"Failed to add leader for partitions %s; will retry"</span>.format(leaderForPartitionsMap.keySet.mkString(<span class="string">","</span>)), t)</div><div class="line">          lock.lock()</div><div class="line">          noLeaderPartitionSet ++= leaderForPartitionsMap.keySet</div><div class="line">          lock.unlock()</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    shutdownIdleFetcherThreads()</div><div class="line">    <span class="type">Thread</span>.sleep(config.refreshLeaderBackoffMs)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>通过ClientUtils.fetchTopicMetadata方法获取kafka相关元信息数据，主要看addFetcherForPartitions方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addFetcherForPartitions</span></span>(partitionAndOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">BrokerAndInitialOffset</span>]) &#123;</div><div class="line">  mapLock synchronized &#123;</div><div class="line">    <span class="keyword">val</span> partitionsPerFetcher = partitionAndOffsets.groupBy&#123; <span class="keyword">case</span>(topicAndPartition, brokerAndInitialOffset) =&gt;</div><div class="line">      <span class="type">BrokerAndFetcherId</span>(brokerAndInitialOffset.broker, getFetcherId(topicAndPartition.topic, topicAndPartition.partition))&#125;</div><div class="line">    <span class="keyword">for</span> ((brokerAndFetcherId, partitionAndOffsets) &lt;- partitionsPerFetcher) &#123;</div><div class="line">      <span class="keyword">var</span> fetcherThread: <span class="type">AbstractFetcherThread</span> = <span class="literal">null</span></div><div class="line">      fetcherThreadMap.get(brokerAndFetcherId) <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(f) =&gt; fetcherThread = f</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">          fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)</div><div class="line">          fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)</div><div class="line">          fetcherThread.start</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      fetcherThreadMap(brokerAndFetcherId).addPartitions(partitionAndOffsets.map &#123; <span class="keyword">case</span> (topicAndPartition, brokerAndInitOffset) =&gt;</div><div class="line">        topicAndPartition -&gt; brokerAndInitOffset.initOffset</div><div class="line">      &#125;)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  info(<span class="string">"Added fetcher for partitions %s"</span>.format(partitionAndOffsets.map&#123; <span class="keyword">case</span> (topicAndPartition, brokerAndInitialOffset) =&gt;</div><div class="line">    <span class="string">"["</span> + topicAndPartition + <span class="string">", initOffset "</span> + brokerAndInitialOffset.initOffset + <span class="string">" to broker "</span> + brokerAndInitialOffset.broker + <span class="string">"] "</span>&#125;))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>BrokerAndFetcherId由broker和一个拉取线程号组成，拉取线程数量通过num.consumer.fetchers参数控制，默认为1，即一个broker有1个拉取线程，相当于默认kafka会创建broker数量个拉取线程，用于从broker处拉取消息，创建拉取线程见createFetcherThread</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createFetcherThread</span></span>(fetcherId: <span class="type">Int</span>, sourceBroker: <span class="type">Broker</span>): <span class="type">AbstractFetcherThread</span> = &#123;</div><div class="line">  <span class="keyword">new</span> <span class="type">ConsumerFetcherThread</span>(</div><div class="line">    <span class="string">"ConsumerFetcherThread-%s-%d-%d"</span>.format(consumerIdString, fetcherId, sourceBroker.id),</div><div class="line">    config, sourceBroker, partitionMap, <span class="keyword">this</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到线程名字是ConsumerFetcherThread，之前看到线程堆栈的就是这里的线程阻塞在了put方法上，接下来根据线程堆栈的信息往下看</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>() &#123;</div><div class="line">  inLock(partitionMapLock) &#123;</div><div class="line">    <span class="keyword">if</span> (partitionMap.isEmpty)</div><div class="line">      partitionMapCond.await(<span class="number">200</span>L, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">    partitionMap.foreach &#123;</div><div class="line">      <span class="keyword">case</span>((topicAndPartition, offset)) =&gt;</div><div class="line">        fetchRequestBuilder.addFetch(topicAndPartition.topic, topicAndPartition.partition,</div><div class="line">                         offset, fetchSize)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> fetchRequest = fetchRequestBuilder.build()</div><div class="line">  <span class="keyword">if</span> (!fetchRequest.requestInfo.isEmpty)</div><div class="line">    processFetchRequest(fetchRequest)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>partitionMap的key是topic+partitionId，value是PartitionTopicInfo，这里将所有的topic，partition还有offset和拉取消息数量，传入fetchRequestBuilder，创建了一个FetchRequest</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processFetchRequest</span></span>(fetchRequest: <span class="type">FetchRequest</span>) &#123;</div><div class="line">  <span class="keyword">val</span> partitionsWithError = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">TopicAndPartition</span>]</div><div class="line">  <span class="keyword">var</span> response: <span class="type">FetchResponse</span> = <span class="literal">null</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    trace(<span class="string">"Issuing to broker %d of fetch request %s"</span>.format(sourceBroker.id, fetchRequest))</div><div class="line">    response = simpleConsumer.fetch(fetchRequest)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</div><div class="line">      <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">        warn(<span class="string">"Error in fetch %s. Possible cause: %s"</span>.format(fetchRequest, t.toString))</div><div class="line">        partitionMapLock synchronized &#123;</div><div class="line">          partitionsWithError ++= partitionMap.keys</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  fetcherStats.requestRate.mark()</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (response != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="comment">// process fetched data</span></div><div class="line">    inLock(partitionMapLock) &#123;</div><div class="line">      response.data.foreach &#123;</div><div class="line">        <span class="keyword">case</span>(topicAndPartition, partitionData) =&gt;</div><div class="line">          <span class="keyword">val</span> (topic, partitionId) = topicAndPartition.asTuple</div><div class="line">          <span class="keyword">val</span> currentOffset = partitionMap.get(topicAndPartition)</div><div class="line">          <span class="comment">// we append to the log if the current offset is defined and it is the same as the offset requested during fetch</span></div><div class="line">          <span class="keyword">if</span> (currentOffset.isDefined &amp;&amp; fetchRequest.requestInfo(topicAndPartition).offset == currentOffset.get) &#123;</div><div class="line">            partitionData.error <span class="keyword">match</span> &#123;</div><div class="line">              <span class="keyword">case</span> <span class="type">ErrorMapping</span>.<span class="type">NoError</span> =&gt;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> messages = partitionData.messages.asInstanceOf[<span class="type">ByteBufferMessageSet</span>]</div><div class="line">                  <span class="keyword">val</span> validBytes = messages.validBytes</div><div class="line">                  <span class="keyword">val</span> newOffset = messages.shallowIterator.toSeq.lastOption <span class="keyword">match</span> &#123;</div><div class="line">                    <span class="keyword">case</span> <span class="type">Some</span>(m: <span class="type">MessageAndOffset</span>) =&gt; m.nextOffset</div><div class="line">                    <span class="keyword">case</span> <span class="type">None</span> =&gt; currentOffset.get</div><div class="line">                  &#125;</div><div class="line">                  partitionMap.put(topicAndPartition, newOffset)</div><div class="line">                  fetcherLagStats.getFetcherLagStats(topic, partitionId).lag = partitionData.hw - newOffset</div><div class="line">                  fetcherStats.byteRate.mark(validBytes)</div><div class="line">                  <span class="comment">// Once we hand off the partition data to the subclass, we can't mess with it any more in this thread</span></div><div class="line">                  processPartitionData(topicAndPartition, currentOffset.get, partitionData)</div><div class="line">                &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                  <span class="keyword">case</span> ime: <span class="type">InvalidMessageException</span> =&gt;</div><div class="line">                    <span class="comment">// we log the error and continue. This ensures two things</span></div><div class="line">                    <span class="comment">// 1. If there is a corrupt message in a topic partition, it does not bring the fetcher thread down and cause other topic partition to also lag</span></div><div class="line">                    <span class="comment">// 2. If the message is corrupt due to a transient state in the log (truncation, partial writes can cause this), we simply continue and</span></div><div class="line">                    <span class="comment">//    should get fixed in the subsequent fetches</span></div><div class="line">                    logger.error(<span class="string">"Found invalid messages during fetch for partition ["</span> + topic + <span class="string">","</span> + partitionId + <span class="string">"] offset "</span> + currentOffset.get + <span class="string">" error "</span> + ime.getMessage)</div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"error processing data for partition [%s,%d] offset %d"</span></div><div class="line">                                             .format(topic, partitionId, currentOffset.get), e)</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> <span class="type">ErrorMapping</span>.<span class="type">OffsetOutOfRangeCode</span> =&gt;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                  <span class="keyword">val</span> newOffset = handleOffsetOutOfRange(topicAndPartition)</div><div class="line">                  partitionMap.put(topicAndPartition, newOffset)</div><div class="line">                  error(<span class="string">"Current offset %d for partition [%s,%d] out of range; reset offset to %d"</span></div><div class="line">                    .format(currentOffset.get, topic, partitionId, newOffset))</div><div class="line">                &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                  <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                    error(<span class="string">"Error getting offset for partition [%s,%d] to broker %d"</span>.format(topic, partitionId, sourceBroker.id), e)</div><div class="line">                    partitionsWithError += topicAndPartition</div><div class="line">                &#125;</div><div class="line">              <span class="keyword">case</span> _ =&gt;</div><div class="line">                <span class="keyword">if</span> (isRunning.get) &#123;</div><div class="line">                  error(<span class="string">"Error for partition [%s,%d] to broker %d:%s"</span>.format(topic, partitionId, sourceBroker.id,</div><div class="line">                    <span class="type">ErrorMapping</span>.exceptionFor(partitionData.error).getClass))</div><div class="line">                  partitionsWithError += topicAndPartition</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>通过simpleConsumer.fetch(fetchRequest)方法向当前这一台broker拉取一批消息，一次请求会拉取当前consumer所需要的所有topic所有partition下的一组消息，response.data的key是topic+partition，value是对应的一组消息，看processPartitionData方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">processPartitionData</span></span>(topicAndPartition: <span class="type">TopicAndPartition</span>, fetchOffset: <span class="type">Long</span>, partitionData: <span class="type">FetchResponsePartitionData</span>) &#123;</div><div class="line">  <span class="keyword">val</span> pti = partitionMap(topicAndPartition)</div><div class="line">  <span class="keyword">if</span> (pti.getFetchOffset != fetchOffset)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>(<span class="string">"Offset doesn't match for partition [%s,%d] pti offset: %d fetch offset: %d"</span></div><div class="line">                              .format(topicAndPartition.topic, topicAndPartition.partition, pti.getFetchOffset, fetchOffset))</div><div class="line">  pti.enqueue(partitionData.messages.asInstanceOf[<span class="type">ByteBufferMessageSet</span>])</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从partitionMap根据topicAndPartition获取PartitionTopicInfo</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">enqueue</span></span>(messages: <span class="type">ByteBufferMessageSet</span>) &#123;</div><div class="line">  <span class="keyword">val</span> size = messages.validBytes</div><div class="line">  <span class="keyword">if</span>(size &gt; <span class="number">0</span>) &#123;</div><div class="line">    <span class="keyword">val</span> next = messages.shallowIterator.toSeq.last.nextOffset</div><div class="line">    trace(<span class="string">"Updating fetch offset = "</span> + fetchedOffset.get + <span class="string">" to "</span> + next)</div><div class="line">    chunkQueue.put(<span class="keyword">new</span> <span class="type">FetchedDataChunk</span>(messages, <span class="keyword">this</span>, fetchedOffset.get))</div><div class="line">    fetchedOffset.set(next)</div><div class="line">    debug(<span class="string">"updated fetch offset of (%s) to %d"</span>.format(<span class="keyword">this</span>, next))</div><div class="line">    consumerTopicStats.getConsumerTopicStats(topic).byteRate.mark(size)</div><div class="line">    consumerTopicStats.getConsumerAllTopicStats().byteRate.mark(size)</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span>(messages.sizeInBytes &gt; <span class="number">0</span>) &#123;</div><div class="line">    chunkQueue.put(<span class="keyword">new</span> <span class="type">FetchedDataChunk</span>(messages, <span class="keyword">this</span>, fetchedOffset.get))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>调用PartitionTopicInfo.enqueue方法将这个topicAndPartition下的一组消息添加到chunkQueue这个队列中，这个队列就是创建KafkaStream时创建的LinkedBlockingQueue了。</p>
<h3 id="kafka线程模型"><a href="#kafka线程模型" class="headerlink" title="kafka线程模型"></a>kafka线程模型</h3><p>根据对线程堆栈以及源码的分析，得到kafka的线程模型：</p>
<ul>
<li><p>消息消费侧：kafka每个消费线程会处理一个topic的部分partition，对应着一个kafkaStream，每个kafkaStream会对应一个LinkedBlockingQueue缓存消息，每次消费线程消费消息时会从对应队列中获取消息；</p>
</li>
<li><p>消息拉取侧：kafka会根据broker数量和num.consumer.fetchers参数创建若干消息拉取线程，用于连接broker拉取消息，然后填充到各消费线程对应的LinkedBlockingQueue上。</p>
</li>
</ul>
<p>两侧的线程通过LinkedBlockingQueue进行连接。</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>kafka的每个消息拉取线程每次会拉取所有topic的消息，put到一个队列中，当我们sleep一个topic的消费线程时，该topic对应的LinkedBlockingQueue队列中的数据得不到消费线程take，很快就满了，消息拉取线程拉取到消息向各个topic对应的LinkedBlockingQueue添加消息的时候，当向该停止消费的topic的LinkedBlockingQueue进行put的时候发现队列满了就会阻塞住，影响了向其他topic对应的LinkedBlockingQueue进行put了，所以其他topic也获取不到消息了。最终所有的拉取线程全部都阻塞在停止消费的这个topic对应队列的put方法上了。</p>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>一个topic使用一个ConsumerConnector，那么就在消息拉取线程上做到了topic维度的完全隔离，就可以使用这种在消费线程sleep这种停止消费方案了。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://blogxin.cn/2018/08/11/kafka-block/" data-id="cjkqq46hu00303r6zcnle0wdq" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABy0lEQVR42u3aQY7DIAwF0N7/0p1tNpBvHGg0ellVqAqPLCxj+/OJn+/lua6Mfl9Xkrc9/ODi4ra53+kz+s98fX6M5D3DI+Hi4h7kjiLG/D/JZvnnmBtwcXHfzM0TlOSQuLi4/487T1aqK7i4uG/jrqUgnYC1/a6Gi4vb4OZVyn2/t9R3cXFxl7j9EkY1TWkVUHBxcY9w84Ayb5ZU11v74uLibubOt1lre1TDX/Ke4XfFxcXdzM2HJ6rtk+Q9UUEWFxf3CLealFSLm9UBrELoxMXF3catti76Y1XVVmtUxcHFxX2Um790rV26ZWALFxf3OHe+WR56qkWTfIQLFxd3N7eKyxst/TGvm8sPLi7uNm6noJlD14osrbiLi4v7KLc6bpVsUA1kNwkTLi7uQe5aGbRzWaqGOVxc3F9xn7rSdEY3ossPLi7uT7n5yEUnlckbLbi4uLu5a2NS+aUovyZFB8PFxT3CrQaXTmukPGZRTI9wcXGf5ebpS95cqbZJkhYLLi7ueW4eaNaOlF+HorsaLi7uy7idHCovtdwUR3BxcV/PTbbpjFy0UhxcXNwGtzw6Ga/nl5zoY+Hi4h7hVoPLGmLt8K36Li4u7gr3D7jFcbAXYJR/AAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/MQ/">MQ</a><a href="/tags/线上问题/">线上问题</a><a href="/tags/源码/">源码</a></div><div class="post-nav"><a class="next" href="/2018/04/23/Distributed-Transaction/">分布式事务</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '530c0141e83989b1dc02',
  clientSecret: '89e61ba0adc9b0c630bcc2641c791bfd7ef9faea',
  repo: 'kris-liu.github.io',
  owner: 'kris-liu',
  admin: ['kris-liu'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://blogxin.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Concurrent/">Concurrent</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/IO-NIO/">IO&NIO</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Netty/">Netty</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tomcat/">Tomcat</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构/">架构</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/线上问题/">线上问题</a><span class="category-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/锁/" style="font-size: 15px;">锁</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/Transaction/" style="font-size: 15px;">Transaction</a> <a href="/tags/MQ/" style="font-size: 15px;">MQ</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/GC/" style="font-size: 15px;">GC</a> <a href="/tags/线上问题/" style="font-size: 15px;">线上问题</a> <a href="/tags/IO/" style="font-size: 15px;">IO</a> <a href="/tags/NIO/" style="font-size: 15px;">NIO</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/并发/" style="font-size: 15px;">并发</a> <a href="/tags/源码/" style="font-size: 15px;">源码</a> <a href="/tags/内存泄漏/" style="font-size: 15px;">内存泄漏</a> <a href="/tags/异步/" style="font-size: 15px;">异步</a> <a href="/tags/缓存/" style="font-size: 15px;">缓存</a> <a href="/tags/读写锁/" style="font-size: 15px;">读写锁</a> <a href="/tags/线程池/" style="font-size: 15px;">线程池</a> <a href="/tags/BIO/" style="font-size: 15px;">BIO</a> <a href="/tags/AIO/" style="font-size: 15px;">AIO</a> <a href="/tags/JMM/" style="font-size: 15px;">JMM</a> <a href="/tags/内存模型/" style="font-size: 15px;">内存模型</a> <a href="/tags/Netty/" style="font-size: 15px;">Netty</a> <a href="/tags/Tomcat/" style="font-size: 15px;">Tomcat</a> <a href="/tags/Tools/" style="font-size: 15px;">Tools</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/11/kafka-block/">由一次kafka消费端消息阻塞问题分析kafka消费端线程模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/23/Distributed-Transaction/">分布式事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/16/java-reference/">Java的强引用，软引用，弱引用，虚引用及其使用场景</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/27/InternalResourceViewResolver-Memory-Leak/">InternalResourceViewResolver引起的内存泄漏问题排查</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/Space-Based-Architecture/">基于空间的架构实践及思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/23/Netty-DataPacket/">Netty源码分析 解决TCP粘包拆包问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/22/jrebel-remote-server/">IntelliJ IDEA下使用JRebel远程热部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/10/Netty-Bootstrap/">Netty源码分析 Bootstrap客户端启动</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/01/Netty-ServerBootstrap/">Netty源码分析 ServerBootstrap服务端启动</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/20/Netty-epollbug/">Netty源码分析 解决NIO的epoll死循环bug</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://blog.csdn.net/xx_ytm" title="我的CSDN博客" target="_blank">我的CSDN博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Liu Xin's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>